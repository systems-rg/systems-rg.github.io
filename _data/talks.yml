- title: "Snowboard: Finding Kernel Concurrency Bugs through Systematic Inter-thread Communication Analysis"
  abbrvenue: SOSP
  year: 2021
  url: "https://dl.acm.org/doi/10.1145/3477132.3483549"
  speaker: Subodh Vishnu Sharma
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1656346085752?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  spurl: "https://subodhvsharma.github.io/"
  when: "1-2:30 pm, 1 Jul 2022"
  abstract: >- 
    Kernel concurrency bugs are challenging to find because they
    depend on very specific thread interleavings and test inputs. While separately
    exploring kernel thread interleavings or test inputs has been closely
    examined, jointly exploring interleavings and test inputs has received little
    attention, in part due to the resulting vast search space. Using precious,
    limited testing resources to explore this search space and execute just the
    right concurrent tests in the proper order is critical.
  
    This paper proposes Snowboard a testing framework that generates and executes
    concurrent tests by intelligently exploring thread interleavings and test
    inputs jointly. The design of Snowboard is based on a concept called potential
    memory communication (PMC), a guess about pairs of tests that, when executed
    concurrently, are likely to perform memory accesses to shared addresses, which
    in turn may trigger concurrency bugs. To identify PMCs, Snowboard runs tests
    sequentially from a fixed initial kernel state, collecting their memory
    accesses. It then pairs up tests that write and read the same region into
    candidate concurrent tests. It executes those tests using the associated PMC
    as a scheduling hint to focus interleaving search only on those schedules that
    directly affect the relevant memory accesses. By clustering candidate tests on
    various features of their PMCs, Snowboard avoids testing similar behaviors,
    which would be inefficient. Finally, by executing tests from small clusters
    first, it prioritizes uncommon suspicious behaviors that may have received
    less scrutiny.
  
    Snowboard discovered 14 new concurrency bugs in Linux kernels 5.3.10 and
    5.12-rc3, of which 12 have been confirmed by developers. Six of these bugs
    cause kernel panics and filesystem errors, and at least two have existed in
    the kernel for many years, showing that this approach can uncover
    hard-to-find, critical bugs. Furthermore, we show that covering as many
    distinct pairs of uncommon read/write instructions as possible is the
    test-prioritization strategy with the highest bug yield for a given test-time
    budget.
  
- title: "Lasagne: a static binary translator for weak memory model architectures"
  abbrvenue: PLDI
  year: 2022
  url: "https://dl.acm.org/doi/abs/10.1145/3519939.3523719"
  speaker: Divyanjali
  spurl: "https://www.cse.iitd.ac.in/~divyanjali/"
  slides: "slides/2022-06-24-lasagne.pdf"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1655825890860?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220624_130306-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 24 Jun 2022"
  abstract: >-
    The emergence of new architectures create a recurring challenge to ensure
    that existing programs still work on them. Manually porting legacy code is
    often impractical. Static binary translation (SBT) is a process where a
    program's binary is automatically translated from one architecture to
    another, while preserving their original semantics. However, these SBT tools
    have limited support to various advanced architectural features.
    Importantly, they are currently unable to translate concurrent binaries. The
    main challenge arises from the mismatches of the memory consistency model
    specified by the different architectures, especially when porting existing
    binaries to a weak memory model architecture.
    
    In this paper, we propose Lasagne, an end-to-end static binary translator
    with precise translation rules between x86 and Arm concurrency semantics.
    First, we propose a concurrency model for Lasagne's intermediate
    representation (IR) and formally proved mappings between the IR and the two
    architectures. The memory ordering is preserved by introducing fences in the
    translated code. Finally, we propose optimizations focused on raising the
    level of abstraction of memory address calculations and reducing the number
    of fences. Our evaluation shows that Lasagne reduces the number of fences by
    up to about 65%, with an average reduction of 45.5%, significantly reducing
    their runtime overhead.

- title: "Log-structured Protocols in Delos"
  abbrvenue: SOSP
  year: 2021
  url: "https://dl.acm.org/doi/10.1145/3477132.3483544"
  speaker: "Ramita Sardana"
  slides: "slides/2022-06-10-delos-engines.pdf"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1654259923536?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220610_130132-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 10 Jun 2022"
  abstract: >-
    Developers have access to a wide range of storage APIs and functionality in
    large-scale systems, such as relational databases, key-value stores, and
    namespaces. However, this diversity comes at a cost: each API is implemented
    by a complex distributed system that is difficult to develop and operate.
    Delos amortizes this cost by enabling different APIs on a shared codebase
    and operational platform. The primary innovation in Delos is a
    log-structured protocol: a fine-grained replicated state machine executing
    above a shared log that can be layered into reusable protocol stacks under
    different databases. We built and deployed two production databases using
    Delos at Facebook, creating nine different log-structured protocols in the
    process. We show via experiments and production data that log-structured
    protocols impose low overhead, while allowing optimizations that can improve
    latency by up to 100X (e.g., via leasing) and throughput by up to 2X (e.g.,
    via batching).


- title: "MVEDSUA: Higher Availability Dynamic Software Updates via Multi-Version Execution"
  abbrvenue: ASPLOS
  year: 2019
  url: "https://dl.acm.org/doi/10.1145/3297858.3304063"
  speaker: "Vishal Singh"
  spurl: "https://www.linkedin.com/in/tmibvishal"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1653659308022?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220603_130154-Meeting%20Recording.mp4?web=1"
  slides: "slides/2022-06-03-mvedsua.pptx"
  when: "1-2:30 pm, 3 Jun 2022"
  abstract: >-
    Dynamic Software Updating (DSU) is a technique for patching stateful
    software without shutting it down, which enables both timely updates and
    non-stop service. Unfortunately, bugs in the update itself—whether in the
    changed code or in the way the change is introduced dynamically—may cause
    the updated software to crash or misbehave. Furthermore, the time taken to
    dynamically apply the update may be unacceptable if it introduces a long
    delay in service.
    
    This paper makes the key observation that both problems can be addressed by
    employing Multi-Version Execution (MVE). To avoid delay in service, the
    update is applied to a forked copy while the original system continues to
    operate.  Once the update completes, the MVE system monitors that the
    responses of both versions agree for the same inputs. Expected divergences
    are specified by the programmer using an MVE-specific DSL. Unexpected
    divergences signal possible errors and roll back the update, which simply
    means terminating the updated version and reverting to the original version.
    This is safe because the MVE system keeps the state of both versions in
    sync. If the new version shows no problems after a warmup period, operators
    can make it permanent and discard the original version.
    
    We have implemented this approach, which we call Mvedsua,1 by extending the
    Kitsune DSU framework with Varan, a state-of-the-art MVE system. We have
    used Mvedsua to update several high-performance servers: Redis, Memcached,
    and Vsftpd. Our results show that Mvedsua significantly reduces the
    update-time delay, imposes little overhead in steady state, and easily
    recovers from a variety of update related errors.
 
- title: "Virtual Consensus in Delos"
  abbrvenue: "OSDI"
  year: "2020"
  url: "https://dl.acm.org/doi/abs/10.5555/3488766.3488801"
  speaker: "Prashant Agrawal"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1653279413005?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  slides: "slides/2022-05-27-delos.pdf"
  when: "1-2:30 pm, 27 May 2022"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220527_130155-Meeting%20Recording.mp4?web=1"
  abstract: >-
    Consensus-based replicated systems are complex, monolithic, and difficult to
    upgrade once deployed. As a result, deployed systems do not benefit from
    innovative research, and new consensus protocols rarely reach production. We
    propose virtualizing consensus by virtualizing the shared log API, allowing
    services to change consensus protocols without downtime. Virtualization
    splits the logic of consensus into the VirtualLog, a generic and reusable
    reconfiguration layer; and pluggable ordering protocols called Loglets.
    Loglets are simple, since they do not need to support reconfiguration or
    leader election; diverse, consisting of different protocols, codebases, and
    even deployment modes; and composable, via RAID-like stacking and striping.
    We describe a production database called Delos1 which leverages virtual
    consensus for rapid, incremental development and deployment. Delos reached
    production within 8 months, and 4 months later upgraded its consensus
    protocol without downtime for a 10X latency improvement. Delos can
    dynamically change its performance properties by changing consensus
    protocols: we can scale throughput by up to 10X by switching to a
    disaggregated Loglet, and double the failure threshold of an instance
    without sacrificing throughput via a striped Loglet.
 

- title: "Predictable Accelerator Design with Time-Sensitive Affine Types"
  abbrvenue: "PLDI"
  year: "2020"
  url: "https://dl.acm.org/doi/abs/10.1145/3385412.3385974"
  speaker: "Madhukar Yerraguntla"
  spurl: "https://www.cse.iitd.ac.in/~madhukar/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1652074464673?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220520_130403-Meeting%20Recording.mp4?web=1"
  slides: "slides/2022-05-20-dahlia.pdf"
  when: "1-2:30 pm, 20 May 2022"
  abstract: >-
    Field-programmable gate arrays (FPGAs) provide an opportunity to co-design
    applications with hardware accelerators, yet they remain difficult to
    program.  High-level synthesis (HLS) tools promise to raise the level of
    abstraction by compiling C or C++ to accelerator designs. Repurposing legacy
    software languages, however, requires complex heuristics to map imperative
    code onto hardware structures. We find that the black-box heuristics in HLS
    can be unpredictable: changing parameters in the program that should improve
    performance can counterintuitively yield slower and larger designs. This
    paper proposes a type system that restricts HLS to programs that can
    predictably compile to hardware accelerators. The key idea is to model
    consumable hardware resources with a time-sensitive affine type system that
    prevents simultaneous uses of the same hardware structure. We implement the
    type system in Dahlia, a language that compiles to HLS C++, and show that it
    can reduce the size of HLS parameter spaces while accepting Pareto-optimal
    designs.
    
- title: "Learning-based Memory Allocation for C++ Server Workloads"
  abbrvenue: "ASPLOS"
  year: "2020"
  url: "https://dl.acm.org/doi/10.1145/3373376.3378525"
  speaker: "Ashish Panwar"
  spurl: "https://apanwariisc.github.io/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1652074464673?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  slides: "slides/2022-05-13-llama.pdf"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220513_130147-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 13 May 2022"
  abstract: >-
    Modern C++ servers have memory footprints that vary widely over time,
    causing persistent heap fragmentation of up to 2x from long-lived objects
    allocated during peak memory usage. This fragmentation is exacerbated by the
    use of huge (2MB) pages, a requirement for high performance on large heap
    sizes. Reducing fragmentation automatically is challenging because C++
    memory managers cannot move objects.
    
    This paper presents a new approach to huge page fragmentation. It combines
    modern machine learning techniques with a novel memory manager (LLAMA) that
    manages the heap based on object lifetimes and huge pages (divided into
    blocks and lines). A neural network-based language model predicts lifetime
    classes using symbolized calling contexts. The model learns
    context-sensitive per-allocation site lifetimes from previous runs,
    generalizes over different binary versions, and extrapolates from samples to
    unobserved calling contexts. Instead of size classes, LLAMA's heap is
    organized by lifetime classes that are dynamically adjusted based on
    observed behavior at a block granularity.
    
    LLAMA reduces memory fragmentation by up to 78% while only using huge pages
    on several production servers. We address ML-specific questions such as
    tolerating mispredictions and amortizing expensive predictions across
    application execution. Although our results focus on memory allocation, the
    questions we identify apply to other system-level problems with strict
    latency and resource requirements where machine learning could be applied.
    
- title: "Theseus: an Experiment in Operating System Structure and State Management"
  abbrvenue: "OSDI"
  year: "2020"
  url: "https://dl.acm.org/doi/10.5555/3488766.3488767"
  speaker: "Indrajit Banerjee"
  slides: "slides/2022-05-06-theseus.pdf"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1651514829781?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/%5BOSDI%202020%5D%20Theseus_%20an%20Experiment%20in%20Operating%20System%20Structure%20and%20State%20Management-20220506_130300-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 06 May 2022"
  abstract: >-
    This paper describes an operating system (OS) called Theseus. Theseus is the
    result of multi-year experimentation to redesign and improve OS modularity by
    reducing the states one component holds for another, and to leverage a safe
    programming language, namely Rust, to shift as many OS responsibilities as
    possible to the compiler.

    Theseus embodies two primary contributions. First, an OS structure in which many
    tiny components with clearly-defined, runtime-persistent bounds interact without
    holding states for each other. Second, an intralingual approach that realizes
    the OS itself using language-level mechanisms such that the compiler can enforce
    invariants about OS semantics.

    Theseus's structure, intralingual design, and state management realize live
    evolution and fault recovery for core OS components in ways beyond that of
    existing works.

- title: "iReplayer: In-situ and Identical Record-and-Replay for Multithreaded Applications"
  abbrvenue: "PLDI"
  year: "2018"
  url: "https://dl.acm.org/doi/10.1145/3192366.3192380"
  speaker: "Abhilash Jindal"
  slides: "slides/2022-04-29-iReplay.pptx"
  spurl: "http://abhilash-jindal.com/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1650873821677?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220429_130001-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 29 Apr 2022"
  abstract: >-
    Reproducing executions of multithreaded programs is very challenging due to
    many intrinsic and external non-deterministic factors. Existing RnR systems
    achieve significant progress in terms of performance overhead, but none
    targets the in-situ setting, in which replay occurs within the same process
    as the recording process. Also, most existing work cannot achieve identical
    replay, which may prevent the reproduction of some errors.

    This paper presents iReplayer, which aims to identically replay
    multithreaded programs in the original process (under the "in-situ"
    setting). The novel in-situ and identical replay of iReplayer makes it more
    likely to reproduce errors, and allows it to directly employ debugging
    mechanisms (e.g. watchpoints) to aid failure diagnosis. Currently, iReplayer
    only incurs 3% performance overhead on average, which allows it to be always
    enabled in the production environment. iReplayer enables a range of
    possibilities, and this paper presents three examples: two automatic tools
    for detecting buffer overflows and use-after-free bugs, and one interactive
    debugging tool that is integrated with GDB.

- title: "Optimizing Big-Data Queries Using Program Synthesis"
  abbrvenue: "SOSP"
  year: "2017"
  url: "https://dl.acm.org/doi/10.1145/3132747.3132773"
  speaker: "Aditya Senthilnathan"
  spurl: "https://adityanathan.github.io/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1650191927216?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220422_130125-Meeting%20Recording.mp4?web=1"
  slides: "https://docs.google.com/presentation/d/1UiXqp-wiJtdbjl_GqF4kobfka_Ocf3qYkXNJV-WH2BU/edit?usp=sharing"
  when: "1-2:30 pm, 22 Apr 2022"
  abstract: >-
    Classical query optimization relies on a predefined set of rewrite rules to
    re-order and substitute SQL operators at a logical level. This paper proposes
    Blitz, a system that can synthesize efficient query-specific operators using
    automated program reasoning. Blitz uses static analysis to identify sub-queries
    as potential targets for optimization. For each sub-query, it constructs a
    template that defines a large space of possible operator implementations, all
    restricted to have linear time and space complexity. Blitz then employs program
    synthesis to instantiate the template and obtain a data-parallel operator
    implementation that is functionally equivalent to the original sub-query up to a
    bound on the input size.

    Program synthesis is an undecidable problem in general and often difficult to
    scale, even for bounded inputs. Blitz therefore uses a series of analyses to
    judiciously use program synthesis and incrementally construct complex operators.

    We integrated Blitz with existing big-data query languages by embedding the
    synthesized operators back into the query as User Defined Operators. We
    evaluated Blitz on several production queries from Microsoft running on two
    state-of-the-art query engines: SparkSQL as well as Scope, the big-data engine
    of Microsoft. Blitz produces correct optimizations despite the synthesis being
    bounded. The resulting queries have much more succinct query plans and
    demonstrate significant performance improvements on both big-data systems (1.3x
    --- 4.7x).

- title: "Understanding and Exploiting Optimal Function Inlining"
  abbrvenue: "ASPLOS"
  year: "2022"
  url: "https://dl.acm.org/doi/pdf/10.1145/3503222.3507744"
  speaker: "Sorav Bansal"
  spurl: "https://sorav.compiler.ai/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1649575739086?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  slides: "slides/2022-04-15-inlining.pdf"
  recording: "https://youtu.be/oHk_7zHjTGI"
  when: "1-2:30 pm, 15 Apr 2022"
  abstract: >-
    Inlining is a core transformation in optimizing compilers. It replaces a
    function call (call site) with the body of the called function (callee).
    It helps reduce function call overhead and binary size, and more
    importantly, enables other optimizations. The problem of inlining has been
    extensively studied, but it is far from being solved; predicting which
    inlining decisions are beneficial is nontrivial due to interactions with
    the rest of the compiler pipeline. Previous work has mainly focused on
    designing heuristics for better inlining decisions and has not investigated
    optimal inlining, i.e., exhaustively finding the optimal inlining
    decisions. Optimal inlining is necessary for identifying and exploiting
    missed opportunities and evaluating the state of the art. This paper fills
    this gap through an extensive empirical analysis of optimal inlining using
    the SPEC2017 benchmark suite. Our novel formulation drastically reduces the
    inlining search space size (from 2^349 down to 2^25) and allows us to
    exhaustively evaluate all inlining choices on 1,135 SPEC2017 files. We show
    a significant gap between the state-of-the-art strategy in LLVM and optimal
    inlining when optimizing for binary size, an important, deterministic
    metric independent of workload (in contrast to performance, another
    important metric). Inspired by our analysis, we introduce a simple,
    effective autotuning strategy for inlining that outperforms the state of
    the art by 7% on average (and up to 28%) on SPEC2017, 15% on the source
    code of LLVM itself, and 10% on the source code of SQLite. This work
    highlights the importance of exploring optimal inlining by providing new,
    actionable insight and an effective autotuning strategy that is of
    practical utility.
