- title: "iReplayer: In-situ and Identical Record-and-Replay for Multithreaded Applications"
  abbrvenue: "PLDI"
  year: "2018"
  url: "https://dl.acm.org/doi/10.1145/3192366.3192380"
  speaker: "Abhilash Jindal"
  slides: "slides/2022-04-29-iReplay.pptx"
  spurl: "http://abhilash-jindal.com/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1650873821677?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220429_130001-Meeting%20Recording.mp4?web=1"
  when: "1-2:30 pm, 29 Apr 2022"
  abstract: >-
    Reproducing executions of multithreaded programs is very challenging due to
    many intrinsic and external non-deterministic factors. Existing RnR systems
    achieve significant progress in terms of performance overhead, but none
    targets the in-situ setting, in which replay occurs within the same process
    as the recording process. Also, most existing work cannot achieve identical
    replay, which may prevent the reproduction of some errors.

    This paper presents iReplayer, which aims to identically replay
    multithreaded programs in the original process (under the "in-situ"
    setting). The novel in-situ and identical replay of iReplayer makes it more
    likely to reproduce errors, and allows it to directly employ debugging
    mechanisms (e.g. watchpoints) to aid failure diagnosis. Currently, iReplayer
    only incurs 3% performance overhead on average, which allows it to be always
    enabled in the production environment. iReplayer enables a range of
    possibilities, and this paper presents three examples: two automatic tools
    for detecting buffer overflows and use-after-free bugs, and one interactive
    debugging tool that is integrated with GDB.

- title: "Optimizing Big-Data Queries Using Program Synthesis"
  abbrvenue: "SOSP"
  year: "2017"
  url: "https://dl.acm.org/doi/10.1145/3132747.3132773"
  speaker: "Aditya Senthilnathan"
  spurl: "https://adityanathan.github.io/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1650191927216?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  recording: "https://csciitd.sharepoint.com/sites/SystemsReadingGroup/Shared%20Documents/General/Recordings/Meeting%20in%20_General_-20220422_130125-Meeting%20Recording.mp4?web=1"
  slides: "https://docs.google.com/presentation/d/1UiXqp-wiJtdbjl_GqF4kobfka_Ocf3qYkXNJV-WH2BU/edit?usp=sharing"
  when: "1-2:30 pm, 22 Apr 2022"
  abstract: >-
    Classical query optimization relies on a predefined set of rewrite rules to
    re-order and substitute SQL operators at a logical level. This paper proposes
    Blitz, a system that can synthesize efficient query-specific operators using
    automated program reasoning. Blitz uses static analysis to identify sub-queries
    as potential targets for optimization. For each sub-query, it constructs a
    template that defines a large space of possible operator implementations, all
    restricted to have linear time and space complexity. Blitz then employs program
    synthesis to instantiate the template and obtain a data-parallel operator
    implementation that is functionally equivalent to the original sub-query up to a
    bound on the input size.

    Program synthesis is an undecidable problem in general and often difficult to
    scale, even for bounded inputs. Blitz therefore uses a series of analyses to
    judiciously use program synthesis and incrementally construct complex operators.

    We integrated Blitz with existing big-data query languages by embedding the
    synthesized operators back into the query as User Defined Operators. We
    evaluated Blitz on several production queries from Microsoft running on two
    state-of-the-art query engines: SparkSQL as well as Scope, the big-data engine
    of Microsoft. Blitz produces correct optimizations despite the synthesis being
    bounded. The resulting queries have much more succinct query plans and
    demonstrate significant performance improvements on both big-data systems (1.3x
    --- 4.7x).

- title: "Understanding and Exploiting Optimal Function Inlining"
  abbrvenue: "ASPLOS"
  year: "2022"
  url: "https://dl.acm.org/doi/pdf/10.1145/3503222.3507744"
  speaker: "Sorav Bansal"
  spurl: "https://sorav.compiler.ai/"
  talk: "https://teams.microsoft.com/l/meetup-join/19%3aRCfaq891_efLuFCzx8w4qEjO4sFxH6d_7rQvBkWUwgc1%40thread.tacv2/1649575739086?context=%7b%22Tid%22%3a%22624d5c4b-45c5-4122-8cd0-44f0f84e945d%22%2c%22Oid%22%3a%228865a316-d74a-4cd5-b93a-66a46ac3d1d1%22%7d"
  slides: "slides/2022-04-15-inlining.pdf"
  recording: "https://youtu.be/oHk_7zHjTGI"
  when: "1-2:30 pm, 15 Apr 2022"
  abstract: >-
    Inlining is a core transformation in optimizing compilers. It replaces a
    function call (call site) with the body of the called function (callee).
    It helps reduce function call overhead and binary size, and more
    importantly, enables other optimizations. The problem of inlining has been
    extensively studied, but it is far from being solved; predicting which
    inlining decisions are beneficial is nontrivial due to interactions with
    the rest of the compiler pipeline. Previous work has mainly focused on
    designing heuristics for better inlining decisions and has not investigated
    optimal inlining, i.e., exhaustively finding the optimal inlining
    decisions. Optimal inlining is necessary for identifying and exploiting
    missed opportunities and evaluating the state of the art. This paper fills
    this gap through an extensive empirical analysis of optimal inlining using
    the SPEC2017 benchmark suite. Our novel formulation drastically reduces the
    inlining search space size (from 2^349 down to 2^25) and allows us to
    exhaustively evaluate all inlining choices on 1,135 SPEC2017 files. We show
    a significant gap between the state-of-the-art strategy in LLVM and optimal
    inlining when optimizing for binary size, an important, deterministic
    metric independent of workload (in contrast to performance, another
    important metric). Inspired by our analysis, we introduce a simple,
    effective autotuning strategy for inlining that outperforms the state of
    the art by 7% on average (and up to 28%) on SPEC2017, 15% on the source
    code of LLVM itself, and 10% on the source code of SQLite. This work
    highlights the importance of exploring optimal inlining by providing new,
    actionable insight and an effective autotuning strategy that is of
    practical utility.
